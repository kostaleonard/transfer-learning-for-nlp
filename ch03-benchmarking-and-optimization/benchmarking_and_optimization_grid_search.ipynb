{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3accfa44",
   "metadata": {},
   "source": [
    "# Benchmarking and optimization: grid search\n",
    "\n",
    "In this notebook, we use grid search to tune hyperparameters on the email classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfefa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import email\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f99f6",
   "metadata": {},
   "source": [
    "## Enron and fraudulent emails datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_filepath = \"../data/enron-email-dataset/emails.csv\"\n",
    "# We will preserve the typo in the filename as that is how it appears on Kaggle.\n",
    "fraud_filepath = \"../data/fraudulent-email-corpus/fradulent_emails.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv(enron_filepath)\n",
    "emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691fec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175acc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_messages(df):\n",
    "    messages = []\n",
    "    for item in df[\"message\"]:\n",
    "        e = email.message_from_string(item)\n",
    "        message_body = e.get_payload()\n",
    "        messages.append(message_body)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = extract_messages(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a605e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies_df = pd.DataFrame(bodies)\n",
    "bodies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fraud_filepath, \"r\", encoding=\"latin1\") as infile:\n",
    "    data = infile.read()\n",
    "fraud_emails = data.split(\"From r\")\n",
    "len(fraud_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_bodies = extract_messages(\n",
    "    pd.DataFrame(fraud_emails, columns=[\"message\"], dtype=str)\n",
    ")\n",
    "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\n",
    "fraud_bodies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fraud_bodies_df[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bdbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsamp = 1000\n",
    "maxtokens = 50\n",
    "maxtokenlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    if row in [None, \"\"]:\n",
    "        tokens = \"\"\n",
    "    else:\n",
    "        tokens = str(row).split(\" \")[:maxtokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expressions(row):\n",
    "    tokens = []\n",
    "    try:\n",
    "        for token in row:\n",
    "            token = token.lower()\n",
    "            token = re.sub(r\"[\\W\\d]\", \"\", token)\n",
    "            token = token[:maxtokenlen]\n",
    "            tokens.append(token)\n",
    "    except:\n",
    "        token = \"\"\n",
    "        tokens.append(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bcc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16573e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0436c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_removal(row):\n",
    "    token = [token for token in row if token not in english_stopwords]\n",
    "    token = filter(None, token)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b72d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnronEmails = bodies_df.iloc[:, 0].apply(tokenize)\n",
    "EnronEmails = EnronEmails.apply(stop_word_removal)\n",
    "EnronEmails = EnronEmails.apply(reg_expressions)\n",
    "EnronEmails = EnronEmails.sample(Nsamp)\n",
    "SpamEmails = fraud_bodies_df.iloc[:, 0].apply(tokenize)\n",
    "SpamEmails = SpamEmails.apply(stop_word_removal)\n",
    "SpamEmails = SpamEmails.apply(reg_expressions)\n",
    "SpamEmails = SpamEmails.sample(Nsamp)\n",
    "raw_data = pd.concat((SpamEmails, EnronEmails), axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8073d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_data.shape)\n",
    "print(raw_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories = [\"spam\", \"notspam\"]\n",
    "header = [1] * Nsamp + [0] * Nsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_bag(data):\n",
    "    used_tokens = []\n",
    "    all_tokens = []\n",
    "    for item in data:\n",
    "        for token in item:\n",
    "            if token in all_tokens:\n",
    "                if token not in used_tokens:\n",
    "                    used_tokens.append(token)\n",
    "            else:\n",
    "                all_tokens.append(token)\n",
    "    df = pd.DataFrame(0, index=np.arange(len(data)), columns=used_tokens)\n",
    "    for i, item in enumerate(data):\n",
    "        for token in item:\n",
    "            if token in used_tokens:\n",
    "                df.iloc[i][token] += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnronSpamBag = assemble_bag(raw_data)\n",
    "predictors_emails = [column for column in EnronSpamBag.columns]\n",
    "EnronSpamBag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91432927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffle_data(data, header):\n",
    "    p = np.random.permutation(len(header))\n",
    "    data = data[p]\n",
    "    header = np.asarray(header)[p]\n",
    "    return data, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e0d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, header = unison_shuffle_data(EnronSpamBag.values, header)\n",
    "idx = int(0.7 * data.shape[0])\n",
    "train_x_emails = data[:idx]\n",
    "train_y_emails = header[:idx]\n",
    "test_x_emails = data[idx:]\n",
    "test_y_emails = header[idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0203ae3",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba215dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc00b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Available hyperparameters for tuning RF:\\n{clf.get_params()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"min_samples_leaf\": [1, 2, 3],\n",
    "    \"min_samples_split\": [2, 6, 10],\n",
    "    \"n_estimators\": [10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search.fit(train_x_emails, train_y_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077788df",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(\n",
    "    test_y_emails,\n",
    "    grid_search.best_estimator_.predict(test_x_emails)\n",
    ")\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Estimated accuracy: {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026ee7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
